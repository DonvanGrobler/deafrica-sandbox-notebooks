{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring coastal erosion along Africa's coastline\n",
    "\n",
    "* **Products used:**  \n",
    "[ls8_sr](https://explorer.digitalearth.africa/ls8_sr), [ls9_sr](https://explorer.digitalearth.africa/ls9_sr)  \n",
    "[s2_l2a](https://explorer.digitalearth.africa/s2_l2a)  \n",
    "[s1_rtc](https://explorer.digitalearth.africa/s1_rtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Over 40% of the world’s population lives within 100 km of the coastline. \n",
    "However, coastal environments are constantly changing, with erosion and coastal change presenting a major challenge to valuable coastal infrastructure and important ecological habitats. \n",
    "Up-to-date data on coastal change and erosion is essential for coastal managers to be able to identify and minimise the impacts of coastal change and erosion.  \n",
    "\n",
    "Imagery from satellites such as the NASA/USGS Landsat, Copernicus Sentinel-1/2 program is available for free for the entire planet, making satellite imagery a powerful and cost-effective tool for monitoring coastlines and rivers at regional or national scale.\n",
    "\n",
    "### DE Africa use case\n",
    "The usefulness of optical imagery such as Landsat and Sentinel-2 in the coastal zone can be affected by the presence of clouds, sun-glint over water poor water quality (e.g. sediment) and the influence of tides. The effect of these factors can be reduced by combining individual noisy images into cleaner \"summary\" or composite layers, and filtering the data to focus only on images taken at certain tidal conditions (e.g. mid-tide). These clean, tidally-constrained composite images can then be used to identify and extract the precise boundary between water and land. This allows us to extract accurate shorelines that can be compared across time to reveal hotspots of erosion and coastal change. \n",
    "\n",
    "Radar observations are largely unaffected by cloud cover, so can take reliable measurements of areas in any weather. Radar data is readily available from the ESA/EC Copernicus program’s Sentinel-1 satellites. The two satellites provide all-weather observations, with a revisit time of 6 days. By developing a process to classify the observed pixels as either water or land, it is possible to identify the shoreline from radar data.\n",
    "\n",
    "### Description\n",
    "\n",
    "In this example, we use a simplified version of the [DE Africa Coastlines](https://github.com/digitalearthafrica/deafrica-coastlines.git) method to combine data from Landsat/Sentinel-1/Sentinel-2 satellite with image compositing and tide filtering techniques to accurately map shorelines across time, and identify areas that have changed significantly between 2018 and 2021. \n",
    "The worked example demonstrates how to:\n",
    "1. Query the satellite data and select best available product\n",
    "2. Process the selected data and generate annual composite images for each year\n",
    "3. Extract shorelines and calculate rates of coastal change  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "**To run this analysis**, run all the cells in the notebook, starting with the \"Load packages\" cell.\n",
    "\n",
    "**After finishing the analysis**, return to the \"Analysis parameters\" cell, modify some values (e.g. choose a different location or time period to analyse) and re-run the analysis.\n",
    "There are additional instructions on modifying the notebook at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "First we need to install additional tools from the [DE Africa Coastlines](https://github.com/digitalearthafrica/deafrica-coastlines.git) repository that will allow us to estimate rates of coastal change. \n",
    "> **Note:** If you run into any error messages in this analysis, try restarting the notebook by clicking `Kernel`, then `Restart Kernel and Clear All Outputs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q git+https://github.com/digitalearthafrica/deafrica-coastlines.git --disable-pip-version-check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load key Python packages and supporting functions for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import datacube\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "from deafrica_tools.datahandling import load_ard, mostcommon_crs\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from dea_tools.coastal import model_tides, tidal_tag, pixel_tides, tidal_stats\n",
    "from dea_tools.spatial import subpixel_contours\n",
    "from deafrica_tools.plotting import display_map, rgb, map_shapefile\n",
    "from deafrica_tools.dask import create_local_dask_cluster\n",
    "from coastlines.raster import tide_cutoffs,load_tidal_subset\n",
    "from coastlines.vector import points_on_line, annual_movements, calculate_regressions\n",
    "\n",
    "from scipy.ndimage.filters import uniform_filter\n",
    "from scipy.ndimage.measurements import variance\n",
    "from skimage.filters import threshold_minimum, threshold_otsu\n",
    "from datacube.utils.cog import write_cog\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a Dask cluster\n",
    "\n",
    "Dask can be used to better manage memory use down and conduct the analysis in parallel. \n",
    "For an introduction to using Dask with Digital Earth Africa, see the [Dask notebook](../Beginners_guide/08_Parallel_processing_with_dask.ipynb).\n",
    "\n",
    ">**Note**: We recommend opening the Dask processing window to view the different computations that are being executed; to do this, see the *Dask dashboard in DE Africa* section of the [Dask notebook](../Beginners_guide/08_parallel_processing_with_dask.ipynb).\n",
    "\n",
    "To use Dask, set up the local computing cluster using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = create_local_dask_cluster(return_client=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "Activate the datacube database, which provides functionality for loading and displaying stored Earth observation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"Coastal_erosion_Landsat_Sentinel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n",
    "\n",
    "The following cell set important parameters for the analysis:\n",
    "\n",
    "* `lat`: The central latitude to analyse (e.g. `14.283`).\n",
    "* `lon`: The central longitude to analyse (e.g. `-16.921`).\n",
    "* `buffer`: The number of square degrees to load around the central latitude and longitude. For reasonable loading times, set this as `0.1` or lower.\n",
    "* `time_range`: The date range to analyse (e.g. `('2018', '2021') `)\n",
    "* `time_step`: This parameter allows us to choose the length of the time periods we want to compare: e.g. shorelines for each year, or shorelines for each six months etc. \n",
    "`1Y` will generate one coastline for every year in the dataset; `6M` will produce a coastline for every six months, etc.\n",
    "* `tide_range`: The minimum and maximum proportion of the tidal range to include in the analysis. \n",
    "For example, `tide_range = (0.50, 1.00)` will select all satellite images taken when the tide was greater than the median (i.e. 50th percentile) of all tide heights and less than the maximum (i.e. 100th percentile) of all tide heights. \n",
    "* `lee_filtering`: A boolean variable deciding on whether to apply spatial filtering on Sentinel-1 images.\n",
    "* `filter_size`: An integer number of speckle filtering size for Sentinel-1. Note that no filtering will be applied if `lee_filtering` is set as False.  \n",
    "\n",
    "This allows you to seperate the effect of erosion from the influence of tides by producing shorelines for specific tidal conditions (e.g. low tide, average tide, high tide shorelines etc). \n",
    "\n",
    "**If running the notebook for the first time**, keep the default settings below.\n",
    "This will demonstrate how the analysis works and provide meaningful results.\n",
    "The example explores coastal change in Ponto, Senegal. \n",
    "\n",
    "**To run the notebook for a different area**, make sure Sentinel-2 data is available for the new location, which you can check at the [DE Africa Explorer](https://explorer.digitalearth.africa/).\n",
    "\n",
    "To ensure that the tidal modelling part of this analysis works correctly, please make sure the **centre of the study area is located over water** when setting `lat_range` and `lon_range`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the area of interest\n",
    "lat = -12.4\n",
    "lon = 43.736\n",
    "# lat = -17.474\n",
    "# lon = 43.924\n",
    "\n",
    "buffer =  0.04\n",
    "\n",
    "# Combine central lat,lon with buffer to get area of interest\n",
    "lat_range = (lat - buffer, lat + buffer)\n",
    "lon_range = (lon - buffer, lon + buffer)\n",
    "\n",
    "# Set the range of dates for the analysis, time step and tide range\n",
    "time_range = ('2018', '2021')\n",
    "time_step = '1Y'\n",
    "tide_range = (0.25, 0.75)\n",
    "\n",
    "# whether to implement Lee filtering on Sentinel-1 images\n",
    "lee_filtering=True\n",
    "# Lee filtering size\n",
    "filter_size=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the selected location\n",
    "The next cell will display the selected area on an interactive map.\n",
    "Feel free to zoom in and out to get a better understanding of the area you'll be analysing.\n",
    "Clicking on any point of the map will reveal the latitude and longitude coordinates of that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_map(x=lon_range, y=lat_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query data and select best available product\n",
    "The first step in this analysis is to query in Landsat, Sentinel-2 and Sentinel-1 data for the `lat_range`, `lon_range` and `time_range` we provided above. \n",
    "We use the `load_ard` function to query data from the satellites for the area and time specified.\n",
    "For more information, see the [Using load_ard notebook](../Frequently_used_code/Using_load_ard.ipynb).\n",
    "The function will also automatically mask out clouds from the dataset, allowing us to focus on pixels that contain useful data. \n",
    "\n",
    "### Query Landsat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'query' dictionary object, which contains the longitudes, \n",
    "# latitudes and time provided above\n",
    "query = {\n",
    "    'x': lon_range,\n",
    "    'y': lat_range,\n",
    "    'time': time_range,\n",
    "    'measurements': ['red', 'green', 'blue', 'swir_1'],\n",
    "    'resolution': (-20, 20),\n",
    "}\n",
    "\n",
    "# Identify the most common projection system in the input query \n",
    "output_crs = mostcommon_crs(dc=dc, product='ls8_sr', query=query)\n",
    "\n",
    "# Load available data Landsat 8\n",
    "ds_ls = load_ard(dc=dc, \n",
    "                 products=['ls8_sr', 'ls9_sr'], \n",
    "                 output_crs=output_crs,\n",
    "                 align=(10, 10),\n",
    "                 mask_filters=[(\"opening\", 1), (\"dilation\", 2)],\n",
    "                 dask_chunks={'time': 1},\n",
    "                 group_by='solar_day',\n",
    "                 resampling='bilinear',\n",
    "                 **query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the load is complete, examine the data by printing it in the next cell.\n",
    "The `Dimensions` argument revels the number of time steps in the data set, as well as the number of pixels in the `x` (longitude) and `y` (latitude) dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Sentinel-2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'query' dictionary object, which contains the longitudes,\n",
    "# latitudes and time provided above\n",
    "query = {\n",
    "    'x': lon_range,\n",
    "    'y': lat_range,\n",
    "    'time': time_range,\n",
    "    'measurements': ['red', 'green', 'blue', 'swir_1','nir'],\n",
    "    'resolution': (-10, 10),\n",
    "}\n",
    "# output_crs = \"EPSG:6933\"\n",
    "\n",
    "# Load available data\n",
    "ds_s2 = load_ard(dc=dc,\n",
    "              products=['s2_l2a'],\n",
    "              output_crs=output_crs,\n",
    "              resampling='bilinear',\n",
    "              align=(5, 5),\n",
    "              mask_filters=[(\"opening\", 2), (\"dilation\", 5)],\n",
    "              dask_chunks={'time': 1},\n",
    "              group_by='solar_day',\n",
    "              **query)\n",
    "print(ds_s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Sentinel-1 data\n",
    "Each of the Sentinel-1 observations was acquired from either a descending or ascending orbit, which has impacts on the local incidence angle and backscattering value. So we first load Sentinel-1 data ascending and descending orbit separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'query' dictionary object, which contains the longitudes,\n",
    "# latitudes and time provided above\n",
    "query = {\n",
    "    'x': lon_range,\n",
    "    'y': lat_range,\n",
    "    'time': time_range,\n",
    "    'measurements': ['vh','vv','mask'],\n",
    "    'resolution': (-20, 20),\n",
    "}\n",
    "ds_s1_ascending=load_ard(dc=dc,\n",
    "              products=['s1_rtc'],\n",
    "              output_crs=output_crs,\n",
    "              resampling='bilinear',\n",
    "              #align=(5, 5),\n",
    "              dask_chunks={'time': 1},\n",
    "              group_by='solar_day',\n",
    "              dtype='native',\n",
    "              sat_orbit_state='ascending',\n",
    "              **query)\n",
    "ds_s1_descending=load_ard(dc=dc,\n",
    "              products=['s1_rtc'],\n",
    "              output_crs=output_crs,\n",
    "              resampling='bilinear',\n",
    "#               align=(5, 5),\n",
    "              dask_chunks={'time': 1},\n",
    "              group_by='solar_day',\n",
    "              dtype='native',\n",
    "              sat_orbit_state='descending',\n",
    "              **query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To minimise the effects of inconsistent looking angle and obit direction for each individual pixel, here we filter out observations from the orbit (ascending/descending) with lower frequency over time. We then merge the two datasets together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_s1_ascending[\"isAscending\"] = xr.where(ds_s1_ascending['mask']!=0,1,np.nan)\n",
    "ds_s1_ascending[\"isDescending\"] = xr.where(ds_s1_ascending['mask']!=0,0,np.nan)\n",
    "\n",
    "ds_s1_descending[\"isDescending\"] = xr.where(ds_s1_descending['mask']!=0,1,np.nan)\n",
    "ds_s1_descending[\"isAscending\"] = xr.where(ds_s1_descending['mask']!=0,0,np.nan)\n",
    "\n",
    "S1=xr.concat([ds_s1_ascending,ds_s1_descending],dim='time')\n",
    "ascending_mask=(S1.isAscending.sum(dim='time')>S1.isDescending.sum(dim='time'))\n",
    "descending_mask=(S1.isAscending.sum(dim='time')<=S1.isDescending.sum(dim='time'))\n",
    "S1=S1.where((ascending_mask&(S1.isAscending==1))|(descending_mask&(S1.isDescending==1)),np.nan)\n",
    "# drop all-nan observations\n",
    "S1=S1.dropna(dim='time',how='all')\n",
    "print(S1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot example timestep\n",
    "To visualise Landsat and Sentinel-2 data, use the pre-loaded `rgb` utility function to plot a true colour image for a given time-step. White areas indicate where clouds or other invalid pixels in the image have been masked.\n",
    "\n",
    "To visualise Sentinel-1 data, we can either plot a single band (e.g. vh), or three bands, e.g. vh, vv, vh/vv. Here we plot the three bands as an example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the timesteps to visualise\n",
    "timestep = 10\n",
    "\n",
    "# Generate RGB plots at each timestep\n",
    "rgb(ds_ls, index=timestep, percentile_stretch=[0, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate RGB plots at each timestep\n",
    "rgb(ds_s2, index=timestep, percentile_stretch=[0, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_s1['vh_d_vv']=ds_s1.vh/ds_s1.vv\n",
    "med = ds_s1[['vh','vv','vh_d_vv']].median()\n",
    "(ds_s1[['vh','vv','vh_d_vv']]/med).to_array().plot.imshow(robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Change the value for `timestep` and re-run the cell to plot a different timestep (timesteps are numbered from `0` to `n_time - 1` where `n_time` is the total number of timesteps; see the `time` listing under the `Dimensions` category in the dataset print-out above).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model tide height  \n",
    "\n",
    "For each satellite timestep, we use the `pixel_tides` function to model tide heights into a low-resolution 5 x 5 km grid (matching resolution of the [FES2014 tidal model](https://www.aviso.altimetry.fr/en/data/products/auxiliary-products/global-tide-fes/description-fes2014.html)), then reprojects modelled tides into the spatial extent of our satellite image. We add this new data as a new variable in our satellite dataset to allow each satellite pixel to be analysed and filtered/masked based on the tide height at the exact moment of satellite image acquisition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ls[\"tide_m\"], tides_lowres_ls = pixel_tides(ds_ls, resample=True)\n",
    "ds_s2[\"tide_m\"], tides_lowres_s2 = pixel_tides(ds_s2, resample=True)\n",
    "ds_s1[\"tide_m\"], tides_lowres_s1 = pixel_tides(ds_s1, resample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select best available product  \n",
    "Here we define a rule-based function to decide which of the three available products is most suitable for shoreline mapping for the given location and study period. The rules are based on number and quality of obseravations, tide coverage and variability of observations over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_product(ds_filtered_ls,ds_filtered_s2,ds_filtered_s1):\n",
    "    # calculate mean tidal coverage\n",
    "    # calculate mean number of valid observations\n",
    "    if condition1:\n",
    "        return ds_ls,'ls'\n",
    "    elif condition 2:\n",
    "        return ds_s2,'s2'\n",
    "    else:\n",
    "        return ds_s1,'s1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_selected,product_name=choose_product(ds_ls,ds_s2,ds_s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Above function is intended to provide some guidance on selecting the product. Alternatively you can select a product that is most fit for your purpose by setting the variable `ds_selected`. For example, uncommenting below cell will override above function and set the product to be used as Sentinel-2 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_selected=ds_s2 # uncomment this line to choose Sentinel-2 product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process selected data and generate annual composite images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process selected data\n",
    "To extract shoreline locations, we need to be able to seperate water from land in our study area. \n",
    "To do this, for Landsat or Sentinel-2 we can calculate a water index called the `Modified Normalised Difference Water Index`, or MNDWI. \n",
    "This index uses the ratio of green and Shortwave-Infrared (SWIR) radiation to identify the presence of water [(Xu 2006)](https://doi.org/10.1080/01431160600589179). \n",
    "The formula is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{MNDWI} &= \\frac{(\\text{Green} - \\text{SWIR})}{(\\text{Green} + \\text{SWIR})}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where `Green` is the green band and `SWIR` is the SWIR band. \n",
    "\n",
    "For Sentinel-1 data, as radar observations appear speckly due to random interference of coherent signals from target scatters, we may want to implement speckle filtering using Lee filter, which is one of the popular adaptive speckle filters that takes into account local homogeneity. Besides, it is often useful to convert the backscatter to decible (dB) for analysis. Backscatter in dB unit has a more symmetric noise profile and less skewed value distribution for easier statistical evaluation.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lee_filter(da, size):\n",
    "    \"\"\"\n",
    "    Apply lee filter of specified window size.\n",
    "    Adapted from https://stackoverflow.com/questions/39785970/speckle-lee-filter-in-python\n",
    "\n",
    "    \"\"\"\n",
    "    img = da.values\n",
    "    img_mean = uniform_filter(img, (size, size))\n",
    "    img_sqr_mean = uniform_filter(img**2, (size, size))\n",
    "    img_variance = img_sqr_mean - img_mean**2\n",
    "\n",
    "    overall_variance = variance(img)\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance)\n",
    "    img_output = img_mean + img_weights * (img - img_mean)\n",
    "    \n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if product_name=='ls':\n",
    "    # Calculate the water index\n",
    "    ds_selected = calculate_indices(ds_selected, index='MNDWI', satellite_mission='ls')\n",
    "elif product_name=='s2':\n",
    "    # Calculate the water index\n",
    "    ds_selected = calculate_indices(ds_selected, index='MNDWI', satellite_mission='s2')\n",
    "else:\n",
    "    # The lee filter above doesn't handle null values\n",
    "    # We therefore set null values to 0 before applying the filter\n",
    "    valid = xr.ufuncs.isfinite(ds_selected)\n",
    "    ds_selected = ds_selected.where(valid, 0)\n",
    "\n",
    "    if lee_filtering==True: # do filtering\n",
    "        # Create a new entry in dataset corresponding to filtered VV and VH data\n",
    "        ds_selected[\"filtered_vh\"] = ds_selected.vh.groupby(\"time\").apply(lee_filter, size=filter_size)\n",
    "    else: # don't do filtering\n",
    "        ds_selected[\"filtered_vh\"]=ds_selected[\"vh\"]\n",
    "\n",
    "    # Null pixels should remain null\n",
    "    ds_selected['filtered_vh'] = ds_selected.filtered_vh.where(ds_selected.filtered_vh!=0,np.nan)\n",
    "\n",
    "    # Scale to plot data in decibels\n",
    "    ds_selected['filtered_vh'] = 10 * xr.ufuncs.log10(ds_selected.filtered_vh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine observations into noise-free summary images\n",
    "Individual remote sensing images can be affected by noisy data, e.g. effects of wind on the water. To produce cleaner images that can be compared more easily across time, we can create 'summary' images or composites that combine multiple images into one image to reveal the median or 'typical' appearance of the landscape for a certain time period. In this case, we use the median as the summary statistic because it prevents strong outliers from skewing the data, which would not be the case if we were to use the mean.\n",
    "\n",
    "In the code below, we take the time series of images and combine them into single images for each `time_step`. For example, if `time_step = '2Y'`, the code will produce one new image for each two-year period in the dataset. This step can take **several minutes to load** if the study area is large.\n",
    "\n",
    ">**Note**: We recommend opening the Dask processing window to view the different computations that are being executed; to do this, see the *Dask dashboard in DE Africa* section of the [Dask notebook](../Beginners_guide/08_Parallel_processing_with_dask.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into summary images by `time_step`\n",
    "if (product_name=='ls')or(product_name=='s2'):\n",
    "    var='MNDWI'\n",
    "else:\n",
    "    var='filtered_vh'\n",
    "\n",
    "ds_summaries = (ds_selected[[var]]\n",
    "                 .resample(time=time_step)\n",
    "                 .median('time')\n",
    "                 .compute()\n",
    "                )\n",
    "# Rename time attribute as year\n",
    "ds_summaries = ds_summaries.rename(time='year')\n",
    "\n",
    "# Plot the output summary images\n",
    "ds_summaries[var].plot(col='year',\n",
    "                       cmap='RdBu',\n",
    "                       col_wrap=2,\n",
    "                       robust=True, size=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "When it comes to interpreting the index, **High values (greater than 0, blue colours) typically represent water pixels**, while **low values (less than 0, red colours) represent land**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down Dask client now that we have processed the data we need\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract shorelines and calculate rates of coastal change \n",
    "### Extract shorelines from imagery\n",
    "We now want to extract an accurate shoreline for each of the summary images above. The code below identifies the boundary between land and water by tracing a line along pixels with a given threshold value. For Landsat and Sentinel-2 images, we use a water index value of `0`. \n",
    "\n",
    "For Sentinel-1 images, the threshold is determined using an automatic thresholding method. Here we use the `threshold_minimum` function, which computes the histogram for all backscatter values, smooths it until there are only two maxima and find the minimum in between as the threshold. \n",
    "\n",
    "We use the `subpixel_contours` function to identify the boundary between land and water by tracing a line along pixels with the previously identified threshold value. It returns a vector file with one line for each time step:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (product_name=='ls')or(product_name=='s2'):\n",
    "    threshold=0\n",
    "else:\n",
    "    threshold= threshold_minimum(S1[var].values[~np.isnan(S1[var].values)])\n",
    "\n",
    "contour_gdf = subpixel_contours(da=ds_summaries[var],\n",
    "                                z_values=threshold,\n",
    "                                dim='year',\n",
    "                                crs=S1.geobox.crs,\n",
    "                                output_path=f'annual_shorelines.geojson',\n",
    "                                min_vertices=15)\n",
    "contour_gdf=contour_gdf.set_index('year')\n",
    "# Preview shoreline data\n",
    "contour_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot resampled shorelines on an interactive map\n",
    "The next cell provides an interactive map with an overlay of the shorelines identified in the previous cell. Run it to view the map (this step can take **several minutes to load** if the study area is large).\n",
    "\n",
    "Zoom in to the map below to explore the resulting set of shorelines. \n",
    "Older shorelines are coloured in black, and more recent shorelines in yellow.\n",
    "Hover over the lines to see the time period for each shoreline printed above the map.\n",
    "Using this data, we can easily identify areas of coastline or rivers that have changed significantly over time, or areas that have remained stable over the entire time period. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot shorelines on interactive map\n",
    "contour_gdf.reset_index().explore(\n",
    "    column='year',\n",
    "    cmap='inferno',\n",
    "    tiles=\n",
    "    'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "    attr='ESRI WorldImagery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate rates of coastal change\n",
    "To identify parts of the coastline that are changing rapidly, we can use our annual shoreline data to calculate rates of coastal change in metres per year.\n",
    "This can be particularly useful to reveal hotspots of coastal retreat (e.g. erosion), or hotspots of coastal growth.\n",
    "\n",
    "To do this, we first need to create a set of evenly spaced points at every 30 metres along the most recent shoreline in our dataset. \n",
    "These points will be used to plot rates of coastal change across our study area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract points at every 30 metres along the most recent shoreline\n",
    "points_gdf = points_on_line(contour_gdf, index='2021', distance=20)\n",
    "points_gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a set of modelling points, we can measure distances from each of the points to each annual shoreline. \n",
    "This gives us a table of distances, where negative values (e.g. `-6.5`) indicate that an annual shoreline was located inland of our points, and positive values (e.g. `2.3`) indicate a shoreline was located towards the ocean. Because our points were created along our most recent 2021 shoreline, distances for 2021 will always have a distance of 0 m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each 30 m-spaced point, calculate the distance from\n",
    "# the most recent 2021 shoreline to each other annual shoreline\n",
    "# in the datasets.\n",
    "points_gdf = annual_movements(points_gdf,\n",
    "                              contours_gdf=contour_gdf,\n",
    "                              yearly_ds=ds_summaries,\n",
    "                              baseline_year=2021,\n",
    "                              water_index=var)\n",
    "points_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can calculate annual rates of coastal change (in metres per year) using linear regression. \n",
    "This will add several new columns to our table:\n",
    "\n",
    "* `rate_time`: Annual rates of change (in metres per year) calculated by linearly regressing annual shoreline distances against time (excluding outliers; see `outl_time`). Negative values indicate retreat and positive values indicate growth. \n",
    "* `sig_time`: Significance (p-value) of the linear relationship between annual shoreline distances and time. Small values (e.g. p-value < 0.01 or 0.05) may indicate a coastline is undergoing consistent coastal change through time. \n",
    "* `se_time`: Standard error (in metres) of the linear relationship between annual shoreline distances and time. This can be used to generate confidence intervals around the rate of change given by rate_time (e.g. 95% confidence interval = `se_time * 1.96`)\n",
    "* `outl_time`: Individual annual shoreline are noisy estimators of coastline position that can be influenced by environmental conditions (e.g. clouds, breaking waves, sea spray) or modelling issues (e.g. poor tidal modelling results or limited clear satellite observations). To obtain reliable rates of change, outlier shorelines are excluded using a robust Median Absolute Deviation outlier detection algorithm, and recorded in this column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rates of change using linear regression\n",
    "points_gdf = calculate_regressions(points_gdf=points_gdf,\n",
    "                                   contours_gdf=contour_gdf)\n",
    "points_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot rates of coastal change on an interactive map\n",
    "Now that we have calculated rates of coastal change, we can plot these on an interactive map to identify parts of the coastline that are retreating or growing over time.\n",
    "\n",
    "When the map appears below, hover your mouse over the coloured dots that appear along the coastline for a summary of recent coastal change at those locations. \n",
    "Red dots represent locations that are retreating (e.g. erosion), and blue dots represent locations that are growing.\n",
    "\n",
    "![coastal_change.jpg](../Supplementary_data/Coastal_erosion/coastal_change.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add human-friendly label for plotting\n",
    "points_gdf['Coastal change'] = points_gdf.apply(\n",
    "    lambda x:\n",
    "    f'<h4>This coastline has {\"<b>retreated</b>\" if x.rate_time < 0 else \"<b>grown</b>\"} '\n",
    "    f'by</br><b>{x.rate_time:.2f} m (±{x.se_time:.1f}) per year</b> since '\n",
    "    f'<b>{contour_gdf.index[0]}</b></h4>',\n",
    "    axis=1)\n",
    "points_gdf.loc[points_gdf.sig_time > 0.05, 'Coastal change'] = (\n",
    "    f'<h4>No significant trend of retreat or growth)</h4>')\n",
    "\n",
    "# Add annual shorelines to map\n",
    "m = contour_gdf.reset_index().explore(\n",
    "    column='year',\n",
    "    cmap='inferno',\n",
    "    tiles=\n",
    "    'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "    tooltip=False,\n",
    "    style_kwds={'opacity': 0.5},\n",
    "    attr='ESRI WorldImagery')\n",
    "\n",
    "# Add rates of change to map\n",
    "points_gdf.explore(\n",
    "    m=m,\n",
    "    column='rate_time',\n",
    "    vmin=-5,\n",
    "    vmax=5,\n",
    "    tooltip='Coastal change',\n",
    "    cmap='RdBu',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Important note:** This notebook may produce misleading rates of change for non-coastal waterbodies that might fluctuate naturally year-by-year.\n",
    "The full [Digital Earth Africa Coastlines repository](https://github.com/digitalearthafrica/deafrica-coastlines.git) contains additional methods for producing more accurate rates of change by cleaning and filtering annual shoreline data to focus only on coastal shorelines.\n",
    "\n",
    "### Export rates of change to file\n",
    "Finally, we can export our output rates of change file so that it can be loaded in GIS software (e.g. ESRI ArcGIS or QGIS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gdf.to_crs('EPSG:4326').to_file(output_path.replace('annual_shorelines','rates_of_changes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "When you are done, return to the \"Set up analysis\" cell, modify some values (e.g. `time_range`, `tide_range`, `time_step` or `lat`/`lon`) and rerun the analysis.\n",
    "If you're going to change the location, you'll need to make sure Sentinel-1 data is available for the new location, which you can check at the [DE Africa Explorer](https://explorer.digitalearth.africa/products/). \n",
    "\n",
    "For more information about the method behind this notebook, read the scientific paper:\n",
    "> Bishop-Taylor, R., Nanson, R., Sagar, S., Lymburner, L. (2021). Mapping Australia's dynamic coastline at mean sea level using three decades of Landsat imagery. Remote Sensing of Environment 267, 112734. Available: https://doi.org/10.1016/j.rse.2021.112734"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Compatible datacube version:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last Tested:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime.today().strftime('%Y-%m-%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
