{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object-based filtering of pixel classifications\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Keywords** :index:`data methods; image segmentation`, :index:`data methods; GEOBIA`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Geographic Object-Based Image Analysis (GEOBIA), aims to group pixels together into meaningful image-objects. There are two advantages to a GEOBIA workflow: one, we can reduce the 'salt and pepper' effect typical of classifying pixels; and two, we can increase the computational efficiency of our workflow by grouping pixels into fewer, larger, but more meaningful objects. A review of the emerging trends in GEOBIA can be found in [Chen et al. (2017)](https://www.tandfonline.com/doi/abs/10.1080/15481603.2018.1426092)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "In this notebook, we take the pixel-based classifications generated in the `4_Classify_satellite_data.ipynb` notebook, and filter the classifications by image-objects. To do this, we first need to conduct image segmentation using the function `skimage.segmentation.quickshift`. The image segmentation is conducted on the `NDVI` layer output in the previous notebook.\n",
    "To filter the pixel observations, we assign to each segment the majority (mode) pixel classification using the `scipy.ndimage.measurements import _stats` module. \n",
    "\n",
    "1. Run the image segmentation\n",
    "2. Visualize the segments \n",
    "2. Calculate the **mode** statistic for each segment\n",
    "3. Write the new object-based classification to disk as a COG\n",
    "4. Plot the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Getting started\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datacube.utils.cog import write_cog\n",
    "from scipy.ndimage._measurements import _stats\n",
    "from skimage.segmentation import quickshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Parameters\n",
    "\n",
    "* `pred_tif`: The path and name of the prediction GeoTIFF output in the previous notebook.\n",
    "* `tif_to_seg`: The geotiff to use as an input to the image segmentation, in the default example this was an NDVI layer output in the last notebook.\n",
    "* `results`: A folder location to store the classified GeoTIFFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tif = 'results/prediction.tif'\n",
    "\n",
    "tif_to_seg = 'results/NDVI.tif'\n",
    "\n",
    "results = 'results/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate an object-based classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our mean NDVI xarray into a numpy array\n",
    "ndvi = rioxarray.open_rasterio(tif_to_seg).squeeze().values\n",
    "\n",
    "# Calculate the segments\n",
    "segments = quickshift(ndvi,\n",
    "                      kernel_size=2,\n",
    "                      convert2lab=False,\n",
    "                      max_dist=4,\n",
    "                      ratio=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise segments\n",
    "\n",
    "To help us visualize the segments, we can calculate the zonal mean NDVI for each segment and then we'll plot a zoomed in section of the region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_zonal_mean_qs = scipy.ndimage.mean(input=ndvi,\n",
    "                                            labels=segments,\n",
    "                                            index=segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2, figsize=(16,8), sharey=True)\n",
    "ax[0].imshow(ndvi[1000:2500,1000:2500], cmap='gist_earth_r', vmin=0.1, vmax=0.7)\n",
    "ax[1].imshow(segments_zonal_mean_qs[1000:2500,1000:2500], cmap='gist_earth_r', vmin=0.1, vmax=0.7)\n",
    "ax[0].set_title('Per pixel NDVI, zoomed in');\n",
    "ax[1].set_title('Mean NDVI within segments, zoomed in')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open pixel-based predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rioxarray.open_rasterio(pred_tif).squeeze().drop_vars('band')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mode\n",
    "\n",
    "Within each segment, the majority classification is calculated and assigned to that segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count, _sum =_stats(pred, labels=segments, index=segments)\n",
    "mode = _sum > (count/2)\n",
    "mode = xr.DataArray(mode,  coords=pred.coords, dims=pred.dims, attrs=pred.attrs).astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write result to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_cog(mode, results+ 'prediction_object.tif', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot result\n",
    "\n",
    "Below we plot the the pixel-based classification alongside the newly created object-based classification. You can see the 'salt and pepper' effect of individual pixels being classified as crop has been removed in the object based classification, resulting in a 'cleaner' classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, sharey=True, figsize=(16, 8))\n",
    "pred.plot(ax=axes[0], add_colorbar=False)\n",
    "mode.plot(ax=axes[1], add_colorbar=False)\n",
    "axes[0].set_title('Pixel-based Classification')\n",
    "axes[1].set_title('Object-based Classification (mode)')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended next steps\n",
    "\n",
    "This is the last notebook in the `Scalable Machine Learning on the ODC` workflow! To revist any of the other notebooks, use the links below.\n",
    "\n",
    "1. [Extracting_training_data](1_Extract_training_data.ipynb) \n",
    "2. [Inspect_training_data](2_Inspect_training_data.ipynb)\n",
    "3. [Evaluate_optimize_fit_classifier](3_Evaluate_optimize_fit_classifier.ipynb)\n",
    "4. [Classify_satellite_data](4_Classify_satellite_data.ipynb)\n",
    "5. **Object-based_filtering (this notebook)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last Tested:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime.today().strftime('%Y-%m-%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
